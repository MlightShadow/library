# Ollama + Open WebUI 以及 llama factory 微调

## Ollama

直接下载 安装运行 llama3会自动下载 默认8b版本，要设置局域网可访问需要在环境变量中设置`OLLAMA_HOST` 值设置为`:<端口号>`

## Open WebUI

安装docker

启动服务设置为Ollama服务的ip和端口

wsl环境下需要设置hperv桥接

## llama factory 微调
